{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing the correlation anlaysis of the evolutionary expansion map to various brain maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuromaps version: 0.0.5+41.gf0ed67c\n"
     ]
    }
   ],
   "source": [
    "import neuromaps\n",
    "print(\"neuromaps version:\", neuromaps.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Make sure to have Connectome Workbench installed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run if needed\n",
    "# pip install neuromaps brainspace\n",
    "# pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more imports if needed\n",
    "\n",
    "from neuromaps.datasets import fetch_atlas ## used to access the templates for the coordinate system\n",
    "import nibabel as nib ## used to load system dictionary per key\n",
    "from neuromaps.datasets import available_annotations ## repository of brain maps - spatial maps representing some\n",
    "from neuromaps.datasets import available_tags ## most annotations have “tags” that help to describe the data they represent\n",
    "from neuromaps.datasets import fetch_annotation\n",
    "from neuromaps.datasets import fetch_fsaverage\n",
    "\n",
    "from neuromaps import transforms\n",
    "import netneurotools\n",
    "# possibly need\n",
    "from netneurotools import datasets as nntdata\n",
    "from neuromaps import parcellate\n",
    "from neuromaps.parcellate import Parcellater\n",
    "from neuromaps.images import dlabel_to_gifti\n",
    "# plotting \n",
    "from neuromaps.images import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from neuromaps import plotting\n",
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# sampling\n",
    "from neuromaps import datasets, images, nulls, resampling\n",
    "from neuromaps.resampling import resample_images\n",
    "from neuromaps.stats import compare_images\n",
    "from neuromaps import stats\n",
    "from nilearn.datasets import fetch_atlas_surf_destrieux\n",
    "from neuromaps.nulls import alexander_bloch\n",
    "from neuromaps.stats import compare_images\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from nilearn.surface import load_surf_mesh\n",
    "from brainspace.null_models import SpinPermutations\n",
    "from nilearn.surface import InMemoryMesh, PolyMesh\n",
    "from nilearn.surface import SurfaceImage\n",
    "from nilearn.plotting import view_surf\n",
    "\n",
    "import time\n",
    "# from neuromaps.stats import fdr_correct\n",
    "# for FDR\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Source Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: source_map will be used later in the full_spin_test function\n",
    "source_map = {'source':'hill2010', 'desc':'evoexp', 'space':'fsLR', 'den':'164k'}\n",
    "# Demonstration on fetching the path to the data map file that is used in the full_spin_test function shown later\n",
    "evolutionary_expansion_map = fetch_annotation(**source_map)\n",
    "evolutionary_expansion_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Target Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: these will be used later in the full_spin_test function\n",
    "target_maps = [\n",
    "    {'source':'abagen', 'desc':'genepc1', 'space':'fsaverage', 'den':'10k'},\n",
    "    {'source':'hcps1200', 'desc':'myelinmap', 'space':'fsLR', 'den':'32k'},\n",
    "    {'source':'hcps1200', 'desc':'thickness', 'space':'fsLR', 'den':'32k'},\n",
    "    {'source':'hill2010', 'desc':'devexp', 'space':'fsLR', 'den':'164k'},\n",
    "    {'source':'margulies2016', 'desc':'fcgradient01', 'space':'fsLR', 'den':'32k'},\n",
    "    {'source':'mueller2013', 'desc':'intersubjvar', 'space':'fsLR', 'den':'164k'},\n",
    "\n",
    "    {'source':'raichle', 'desc':'cbf', 'space':'fsLR', 'den':'164k'},\n",
    "    {'source':'raichle', 'desc':'cbv', 'space':'fsLR', 'den':'164k'},\n",
    "    {'source':'raichle', 'desc':'cmr02', 'space':'fsLR', 'den':'164k'},\n",
    "    {'source':'raichle', 'desc':'cmrglc', 'space':'fsLR', 'den':'164k'},\n",
    "    {'source':'reardon2018', 'desc':'scalingnih', 'space':'civet', 'den':'41k'},\n",
    "    {'source':'reardon2018', 'desc':'scalingpnc', 'space':'civet', 'den':'41k'}\n",
    "]\n",
    "\n",
    "# Official names for plotting later\n",
    "map_names = {\n",
    "    'genepc1': 'PC1 Gene Expression',\n",
    "    'myelinmap': 'T1w/T2w Ratio',\n",
    "    'thickness': 'Cortical Thickness',\n",
    "    'devexp': 'Developmental Expansion',\n",
    "    'fcgradient01': 'Functional Gradient',\n",
    "    'intersubjvar': 'Intersubject Variability',\n",
    "    'cbf': 'Cerebral Blood Flow',\n",
    "    'cbv': 'Cerebral Blood Volume',\n",
    "    'cmr02': 'Oxygen Metabolism',\n",
    "    'cmrglc': 'Glucose Metabolism',\n",
    "    'scalingnih': 'Allometric Scaling (NIH)',\n",
    "    'scalingpnc': 'Allometric Scaling (PNC)',\n",
    "    'evoexp': 'Evolutionary Expansion'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the Spin Test for our Target Maps\n",
    "\n",
    "Also demonstrates transforming brain maps to different coordinate systems and densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_spin_test(src: dict, trg: dict):\n",
    "    \"\"\"\n",
    "    Performs the Alexander Bloch spin test between the source map and target map\n",
    "    Parameters:\n",
    "    src: the source map as a dictionary with the needed parameters for feth_annotation\n",
    "    trg: the target maps as a dictionary with the needed parameters for feth_annotation\n",
    "    Outputs: A list of dictionaries \n",
    "    \"\"\"\n",
    "    src_paper, src_desc, src_space, src_den = src.values()\n",
    "    trg_paper, trg_desc, trg_space, trg_den = trg.values()\n",
    "\n",
    "    #fetch source map and target map files\n",
    "    start = time.perf_counter() #timing just for user info\n",
    "    src_map = datasets.fetch_annotation(**src)\n",
    "    trg_map = datasets.fetch_annotation(**trg)\n",
    "\n",
    "    #if target map has both hemispheres, use only the right one\n",
    "    #our source map only contains data for the right hemisphere\n",
    "    if(len(trg_map)==2):\n",
    "        trg_map = trg_map[1]\n",
    "    if src_den != trg_den:\n",
    "        src_res, trg_res = resampling.resample_images(\n",
    "            src_map,\n",
    "            trg_map,\n",
    "            src_space=src_space,\n",
    "            trg_space=trg_space,\n",
    "            hemi='R',\n",
    "            resampling='downsample_only' #sample to size of target map density\n",
    "        )\n",
    "        #load the actual data from the files\n",
    "        src_data = images.load_data(src_res)\n",
    "        trg_data = images.load_data(trg_res)\n",
    "    else:\n",
    "        src_data = images.load_data(src_map)\n",
    "        trg_data = images.load_data(trg_map)\n",
    "    #create nan values for left brain\n",
    "    L_nan = np.full_like(src_data, np.nan)\n",
    "    src_sphere = np.hstack([L_nan, src_data])\n",
    "    trg_sphere = np.hstack([L_nan, trg_data])\n",
    "    #spin test\n",
    "    rotated = nulls.alexander_bloch(\n",
    "        src_sphere,\n",
    "        atlas = trg_space,\n",
    "        density = trg_den,\n",
    "        n_perm = 1000,\n",
    "        seed = 1234\n",
    "    )\n",
    "    r_corr, p_value, null_dist = compare_images(\n",
    "        src_sphere,\n",
    "        trg_sphere,\n",
    "        metric='pearsonr',\n",
    "        nulls=rotated,\n",
    "        return_nulls=True\n",
    "    )\n",
    "    end = time.perf_counter()\n",
    "    time_elapsed = end - start\n",
    "    print(f\"Time elapsed for {trg_desc}: {time_elapsed/60:.2f} minutes\")\n",
    "    \n",
    "    formal_name = map_names.get(trg_desc)\n",
    "    results_dict = {'target map': formal_name, \n",
    "                'r_emp': r_corr, \n",
    "                'p_spin': p_value, \n",
    "                'nulls': null_dist\n",
    "               }\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for trg_map in target_maps:\n",
    "    results.append(full_spin_test(source_map, trg_map))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Discovery Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## False Discovery Rate Calculation\n",
    "## Multiple Comparison Tests\n",
    "\n",
    "p_vals = np.array(results_df['p_spin'])\n",
    "\n",
    "# Benjamini–Hochberg FDR\n",
    "reject_fdr, p_fdr, _, _ = multipletests(p_vals, alpha=0.05, method='fdr_bh')\n",
    "# Bonferroni correction\n",
    "reject_bonf, p_bonf, _, _ = multipletests(p_vals, alpha=0.05, method='bonferroni')\n",
    "\n",
    "results_df['p_FDR'] = p_fdr\n",
    "results_df['reject_FDR'] = reject_fdr\n",
    "results_df['p_Bonf'] = p_bonf\n",
    "results_df['reject_Bonf'] = reject_bonf\n",
    "\n",
    "summary_df = results_df[['target map', 'p_spin', 'p_FDR', 'reject_FDR', 'p_Bonf', 'reject_Bonf']].copy()\n",
    "summary_df.columns = [\n",
    "    'Target map',\n",
    "    'p_spin (uncorrected)',\n",
    "    'p_FDR (BH corrected)',\n",
    "    'Significant (FDR<0.05)',\n",
    "    'p_Bonferroni (corrected)',\n",
    "    'Significant (Bonf<0.05)'\n",
    "]\n",
    "summary_df = summary_df.round(4)\n",
    "\n",
    "print(\"Summary of results:\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Box Plot\n",
    "Our findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for plotting box plots for each target map\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "box_data = [np.ravel(np.array(n)) for n in results_df['nulls']]\n",
    "positions = np.arange(1, len(box_data) + 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 8))\n",
    "#boxplots for target maps null distributions\n",
    "bp = ax.boxplot(\n",
    "    box_data,\n",
    "    positions=positions,\n",
    "    widths=0.6,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='white', edgecolor='black', linewidth=1),\n",
    "    medianprops=dict(color='black', linewidth=1),\n",
    "    whiskerprops=dict(color='black'),\n",
    "    capprops=dict(color='black'),\n",
    "    flierprops=dict(marker='o', color='gray', markersize=3, alpha=0.4)\n",
    ")\n",
    "\n",
    "#add spin test r correlation values\n",
    "for i, (r, p) in enumerate(zip(results_df['r_emp'], results_df['p_spin'])):\n",
    "    color = 'red' if p < 0.05 else '#e6a67a'  # red = significant, orange = non-significant\n",
    "    ax.scatter(\n",
    "        positions[i],\n",
    "        r,\n",
    "        color=color,\n",
    "        s=80,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5,\n",
    "        zorder=3\n",
    "    )\n",
    "\n",
    "ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(results_df['target map'], rotation=40, ha='right', fontsize=10)\n",
    "ax.set_ylabel(\"Pearson's r\", fontsize=12)\n",
    "ax.set_xlabel(\"Target maps\", fontsize=12)\n",
    "ax.set_ylim(-0.8, 0.8)\n",
    "ax.set_title(\"Empirical correlations vs spatial nulls\", fontsize=13, pad=15)\n",
    "\n",
    "#legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w',\n",
    "           label=r'Empirical ($P_{spin} ≥ 0.05$)',\n",
    "           markerfacecolor='#e6a67a', markeredgecolor='black', markersize=8),\n",
    "    Line2D([0], [0], marker='o', color='w',\n",
    "           label=r'Empirical ($P_{spin} < 0.05$)',\n",
    "           markerfacecolor='red', markeredgecolor='black', markersize=8),\n",
    "    Line2D([0], [0], color='black', lw=1, label='Spatial null')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dictionary for target maps plotting\n",
    "\n",
    "brain_map_settings = {\n",
    "    'evoexp': {'cmap': 'inferno', 'vmin': -2.7, 'vmax': 2.7},\n",
    "\n",
    "    'genepc1': {'cmap': 'inferno', 'vmin': -2.7, 'vmax': 2.7},\n",
    "    'myelinmap':{'cmap': 'viridis', 'vmin': None, 'vmax': None},\n",
    "    'thickness': {'cmap': 'viridis', 'vmin': None, 'vmax': None},\n",
    "    'devexp': {'cmap': 'inferno', 'vmin': -1, 'vmax': 1},\n",
    "    'fcgradient01': {'cmap': 'viridis', 'vmin': None, 'vmax': None},\n",
    "    'intersubjvar': {'cmap': 'inferno', 'vmin': None, 'vmax': None},\n",
    "    \n",
    "    'cbf': {'cmap': 'inferno', 'vmin': None, 'vmax': None}, # need to change\n",
    "    'cbv': {'cmap': 'inferno', 'vmin': None, 'vmax': None},\n",
    "    'cmr02': {'cmap': 'inferno', 'vmin': None, 'vmax': None}, # need to change\n",
    "    'cmrglc': {'cmap': 'inferno', 'vmin': None, 'vmax': None}, # need to change\n",
    "    'scalingnih': {'cmap': 'inferno', 'vmin': None, 'vmax': None},\n",
    "    'scalingpnc': {'cmap': 'inferno', 'vmin': None, 'vmax': None},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_brain_map(map: dict, map_names: dict, brain_map_settings: dict):\n",
    "    \"\"\"\n",
    "    Plots the brain map given in the map dictionary\n",
    "    Parameters:\n",
    "    map: the map as a dictionary with the needed parameters for feth_annotation\n",
    "    map_names: dictionary of formal names for readability and plot titles\n",
    "    Outputs: \n",
    "        ...\n",
    "    \"\"\"\n",
    "    start_time  = time.perf_counter() #timing just for user info\n",
    "\n",
    "    map_paper, map_desc, map_space, map_den = map.values()\n",
    "    #fetch source map and target map files\n",
    "    src_map = datasets.fetch_annotation(**map)\n",
    "\n",
    "    settings = brain_map_settings.get(map_desc, {})\n",
    "    cmap = settings.get('cmap', 'inferno')\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    fslr = fetch_atlas(map_space, map_den)\n",
    "    surf_mesh_left = fslr['inflated'].L\n",
    "    surf_mesh_right = fslr['inflated'].R\n",
    "    data_full = load_data(src_map)\n",
    "\n",
    "    if settings.get('vmin') is not None and settings.get('vmax') is not None:\n",
    "        vmin, vmax = settings['vmin'], settings['vmax']\n",
    "    else:\n",
    "        vmin, vmax = np.percentile(data_full[~np.isnan(data_full)], [2, 98])\n",
    "\n",
    "    #if target map has both hemispheres, plot both hemispheres lateral\n",
    "    if(len(src_map)==2):\n",
    "        data_l = load_data(src_map[0])\n",
    "        data_r = load_data(src_map[1])\n",
    "        ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "        plotting.plot_surf(\n",
    "            surf_mesh=surf_mesh_left,\n",
    "            surf_map=data_l,\n",
    "            hemi='left',\n",
    "            view='lateral',\n",
    "            cmap=cmap,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            colorbar=False,\n",
    "            axes=ax1,\n",
    "            title='Left hemisphere'\n",
    "        )\n",
    "        # right hemi\n",
    "        ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "        plotting.plot_surf(\n",
    "            surf_mesh=surf_mesh_right,\n",
    "            surf_map=data_r,\n",
    "            hemi='right',\n",
    "            view='lateral',\n",
    "            cmap=cmap,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            colorbar=False,\n",
    "            axes=ax2,\n",
    "            title='Right hemisphere'\n",
    "        )\n",
    "        # color bar\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "        sm.set_clim(vmin, vmax)\n",
    "        cbar = fig.colorbar(sm, ax=[ax1, ax2], shrink=0.6, location='right')\n",
    "        cbar.set_label(f\"{map_names.get(map_desc)}({map_space} {map_den})\", fontsize=11)\n",
    "        plt.suptitle(f\"{map_names.get(map_desc)}\", fontsize=14)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    else: #if only one hemisphere, only plot that hemisphere lateral and medial\n",
    "        plot_kwargs = dict(\n",
    "            surf_mesh=surf_mesh_right,\n",
    "            surf_map=data_full,\n",
    "            hemi='right',\n",
    "            bg_on_data=True,\n",
    "            cmap=cmap,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            colorbar=False\n",
    "        )\n",
    "        #plot right veiw\n",
    "        ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "        plotting.plot_surf(\n",
    "            view='lateral',\n",
    "            axes=ax1,\n",
    "            **plot_kwargs\n",
    "        )\n",
    "        #plot from left view\n",
    "        ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "        plotting.plot_surf(\n",
    "            view='medial',\n",
    "            axes=ax2,\n",
    "            **plot_kwargs\n",
    "        )\n",
    "        #color bar\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "        sm.set_clim(vmin, vmax)\n",
    "        cbar = fig.colorbar(sm, ax=[ax1, ax2], shrink=0.6, location='right')\n",
    "        cbar.set_label(f\"{map_names.get(map_desc)}({map_space} {map_den})\", fontsize=11)\n",
    "        plt.suptitle(f\"{map_names.get(map_desc)}\", fontsize=14)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"Total time for plotting: {(end_time - start_time):.2f} seconds\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_brain_map(source_map, map_names, brain_map_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trg_map in target_maps:\n",
    "    plot_brain_map(trg_map, map_names, brain_map_settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromaps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
