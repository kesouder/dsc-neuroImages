{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Fetching atlases and annotations\n",
        "\n",
        "This example demonstrates how to use :mod:`neuromaps.datasets` to fetch\n",
        "atlases and annotations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Much of the functionality of the ``neuromaps`` toolbox relies on the\n",
        "atlases and atlas files provided with it. In many cases these atlases are\n",
        "fetched \"behind-the-scenes\" when you call functions that depend on them, but\n",
        "they can be accessed directly.\n",
        "\n",
        "There is a general purpose :func:`neuromaps.datasets.fetch_atlas`\n",
        "function that can fetch any of the atlases provided with ``neuromaps``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/netneurolab/neuromaps.git\n",
            "  Cloning https://github.com/netneurolab/neuromaps.git to /private/var/folders/t2/8t74_04d3t5gx4vjqq895zbh0000gn/T/pip-req-build-_rkj09bd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/netneurolab/neuromaps.git /private/var/folders/t2/8t74_04d3t5gx4vjqq895zbh0000gn/T/pip-req-build-_rkj09bd\n",
            "  Resolved https://github.com/netneurolab/neuromaps.git to commit f0ed67c44d633061b93c6d337a1b233f6895c408\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from neuromaps==0.0.5+41.gf0ed67c) (2.2.4)\n",
            "Requirement already satisfied: scipy>=0.17 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from neuromaps==0.0.5+41.gf0ed67c) (1.15.2)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from neuromaps==0.0.5+41.gf0ed67c) (3.9.2)\n",
            "Requirement already satisfied: scikit-learn in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from neuromaps==0.0.5+41.gf0ed67c) (1.5.2)\n",
            "Requirement already satisfied: nibabel>=3.0.0 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from neuromaps==0.0.5+41.gf0ed67c) (5.3.2)\n",
            "Requirement already satisfied: nilearn in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from neuromaps==0.0.5+41.gf0ed67c) (0.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from matplotlib>=3.5.0->neuromaps==0.0.5+41.gf0ed67c) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from matplotlib>=3.5.0->neuromaps==0.0.5+41.gf0ed67c) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from matplotlib>=3.5.0->neuromaps==0.0.5+41.gf0ed67c) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from matplotlib>=3.5.0->neuromaps==0.0.5+41.gf0ed67c) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from matplotlib>=3.5.0->neuromaps==0.0.5+41.gf0ed67c) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from matplotlib>=3.5.0->neuromaps==0.0.5+41.gf0ed67c) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from matplotlib>=3.5.0->neuromaps==0.0.5+41.gf0ed67c) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from matplotlib>=3.5.0->neuromaps==0.0.5+41.gf0ed67c) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from nibabel>=3.0.0->neuromaps==0.0.5+41.gf0ed67c) (4.12.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from nilearn->neuromaps==0.0.5+41.gf0ed67c) (1.4.2)\n",
            "Requirement already satisfied: lxml in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from nilearn->neuromaps==0.0.5+41.gf0ed67c) (5.2.1)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from nilearn->neuromaps==0.0.5+41.gf0ed67c) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.25.0 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from nilearn->neuromaps==0.0.5+41.gf0ed67c) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from scikit-learn->neuromaps==0.0.5+41.gf0ed67c) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from pandas>=2.2.0->nilearn->neuromaps==0.0.5+41.gf0ed67c) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from pandas>=2.2.0->nilearn->neuromaps==0.0.5+41.gf0ed67c) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->neuromaps==0.0.5+41.gf0ed67c) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from requests>=2.25.0->nilearn->neuromaps==0.0.5+41.gf0ed67c) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from requests>=2.25.0->nilearn->neuromaps==0.0.5+41.gf0ed67c) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from requests>=2.25.0->nilearn->neuromaps==0.0.5+41.gf0ed67c) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/kevinhuang/miniforge3/envs/dsc80/lib/python3.12/site-packages (from requests>=2.25.0->nilearn->neuromaps==0.0.5+41.gf0ed67c) (2025.1.31)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_files</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloading data from \n",
              "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://files.osf.io/v1/resources/4mw3a/providers/osfstorage/60b684b53a6df1021bd4df2d</span> <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_files\u001b[0m\u001b[1;34m]\u001b[0m Downloading data from \n",
              "\u001b[4;94mhttps://files.osf.io/v1/resources/4mw3a/providers/osfstorage/60b684b53a6df1021bd4df2d\u001b[0m \u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_files</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span>  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>done. <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> seconds, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> min<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_files\u001b[0m\u001b[1;34m]\u001b[0m  \u001b[33m...\u001b[0mdone. \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m seconds, \u001b[1;36m0\u001b[0m min\u001b[1m)\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_files</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Extracting data from \n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">/Users/kevinhuang/neuromaps-data/599046a594e0e45c04e90291c2348cbe/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">fsLR32k.tar.gz...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_files\u001b[0m\u001b[1;34m]\u001b[0m Extracting data from \n",
              "\u001b[35m/Users/kevinhuang/neuromaps-data/599046a594e0e45c04e90291c2348cbe/\u001b[0m\u001b[95mfsLR32k.tar.gz...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_files</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> .. done.\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_files\u001b[0m\u001b[1;34m]\u001b[0m .. done.\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['midthickness', 'inflated', 'veryinflated', 'sphere', 'medial', 'sulc', 'vaavg'])\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/netneurolab/neuromaps.git\n",
        "from neuromaps import datasets\n",
        "\n",
        "fslr = datasets.fetch_atlas(atlas='fslr', density='32k')\n",
        "print(fslr.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The values corresponding to the keys of the atlas dictionary are length-2\n",
        "lists containing filepaths to the downloaded data. All surface atlas files\n",
        "are provide in gifti format (whereas MNI files are in gzipped nifti format).\n",
        "\n",
        "You can load them directly with ``nibabel`` to confirm their validity:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32492, 3) (64980, 3)\n"
          ]
        }
      ],
      "source": [
        "import nibabel as nib\n",
        "lsphere, rsphere = fslr['sphere']\n",
        "lvert, ltri = nib.load(lsphere).agg_data()\n",
        "print(lvert.shape, ltri.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The other datasets that are provided with ``neuromaps`` are annotations\n",
        "(i.e., brain maps!). While we are slowly making more and more of these openly\n",
        "available, for now only a subset are accessible to the general public; these\n",
        "are returned by default via :func:`datasets.available_annotations`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available annotations: 86\n"
          ]
        }
      ],
      "source": [
        "annotations = datasets.available_annotations()\n",
        "print(f'Available annotations: {len(annotations)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :func:`~.available_annotations` function accepts a number of keyword\n",
        "arguments that you can use to query specific datasets. For example, providing\n",
        "the `format='volume`' argument will return only those annotations that\n",
        "are, by default, a volumetric image:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available volumetric annotations: 47\n"
          ]
        }
      ],
      "source": [
        "volume_annotations = datasets.available_annotations(format='volume')\n",
        "print(f'Available volumetric annotations: {len(volume_annotations)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are a number of keyword arguments we can specify to reduce the scope of\n",
        "the annotations returned. Here, `source` specifies where the annotation came\n",
        "from (i.e., a dataset from a manuscript or a data repository or toolbox),\n",
        "`desc` refers to a brief description of the annotation, `space` clarifies\n",
        "which space the annotation is in, and `den` (specific to surface annotations)\n",
        "clarifies the density of the surface on which the annotation is defined:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('abagen', 'genepc1', 'fsaverage', '10k')]\n"
          ]
        }
      ],
      "source": [
        "annot = datasets.available_annotations(source='abagen', desc='genepc1',\n",
        "                                       space='fsaverage', den='10k')\n",
        "print(annot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Annotations also have tags to help sort them into categories. You can see\n",
        "what tags can be used to query annotations with the :func:`~.available_tags`\n",
        "functions:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ASL', 'MEG', 'MRI', 'PET', 'fMRI', 'functional', 'genetics', 'meta-analysis', 'metabolism', 'receptors', 'resteyesopen', 'structural']\n"
          ]
        }
      ],
      "source": [
        "tags = datasets.available_tags()\n",
        "print(tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tags can be used as a keyword argument with :func:`~.available_annotations`.\n",
        "You can supply either a single tag or a list of tags. Note that supplying a\n",
        "list will only return those annotations that match ALL supplied tags:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('margulies2016', 'fcgradient01', 'fsLR', '32k'), ('margulies2016', 'fcgradient02', 'fsLR', '32k'), ('margulies2016', 'fcgradient03', 'fsLR', '32k'), ('margulies2016', 'fcgradient04', 'fsLR', '32k'), ('margulies2016', 'fcgradient05', 'fsLR', '32k'), ('margulies2016', 'fcgradient06', 'fsLR', '32k'), ('margulies2016', 'fcgradient07', 'fsLR', '32k'), ('margulies2016', 'fcgradient08', 'fsLR', '32k'), ('margulies2016', 'fcgradient09', 'fsLR', '32k'), ('margulies2016', 'fcgradient10', 'fsLR', '32k'), ('mueller2013', 'intersubjvar', 'fsLR', '164k'), ('neurosynth', 'cogpc1', 'MNI152', '2mm')]\n"
          ]
        }
      ],
      "source": [
        "fmri_annotations = datasets.available_annotations(tags='fMRI')\n",
        "print(fmri_annotations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have an annotation that we want we can use the\n",
        ":func:`neuromaps.datasets.fetch_annotation` to actually download the\n",
        "files. This has a very similar signature to the\n",
        ":func:`~.available_annotations` function, accepting almost all the same\n",
        "keyword arguments to specify which annotations are desired.\n",
        "\n",
        "Here, we'll grab the first principal component of gene expression across the\n",
        "brain (from the Allen Human Brain Atlas):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_single_file</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloading data from \n",
              "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://files.osf.io/v1/resources/4mw3a/providers/osfstorage/60c2290118f70b01fca797eb</span> <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_single_file\u001b[0m\u001b[1;34m]\u001b[0m Downloading data from \n",
              "\u001b[4;94mhttps://files.osf.io/v1/resources/4mw3a/providers/osfstorage/60c2290118f70b01fca797eb\u001b[0m \u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_single_file</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span>  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>done. <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> seconds, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> min<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_single_file\u001b[0m\u001b[1;34m]\u001b[0m  \u001b[33m...\u001b[0mdone. \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m seconds, \u001b[1;36m0\u001b[0m min\u001b[1m)\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_single_file</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloading data from \n",
              "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://files.osf.io/v1/resources/4mw3a/providers/osfstorage/60c228f5f3ce9401fa24e521</span> <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_single_file\u001b[0m\u001b[1;34m]\u001b[0m Downloading data from \n",
              "\u001b[4;94mhttps://files.osf.io/v1/resources/4mw3a/providers/osfstorage/60c228f5f3ce9401fa24e521\u001b[0m \u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_single_file</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span>  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>done. <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> seconds, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> min<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_single_file\u001b[0m\u001b[1;34m]\u001b[0m  \u001b[33m...\u001b[0mdone. \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m seconds, \u001b[1;36m0\u001b[0m min\u001b[1m)\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[References] Please cite the following papers if you are using this data:\n",
            "\n",
            "  For {'source': 'abagen', 'desc': 'genepc1', 'space': 'fsaverage', 'den': '10k'}:\n",
            "  [primary]:\n",
            "    Michael J Hawrylycz, Ed S Lein, Angela L Guillozet-Bongaarts, Elaine H Shen, Lydia Ng, Jeremy A Miller, Louie N Van De Lagemaat, Kimberly A Smith, Amanda Ebbert, Zackery L Riley, and others. An anatomically comprehensive atlas of the adult human brain transcriptome. Nature, 489(7416):391, 2012.\n",
            "    Ross D Markello, Aurina Arnatkeviciute, Jean-Baptiste Poline, Ben D Fulcher, Alex Fornito, and Bratislav Misic. Standardizing workflows in imaging transcriptomics with the abagen toolbox. eLife, 10:e72129, 2021.\n",
            "  [secondary]:\n",
            "    \n",
            "['/Users/kevinhuang/neuromaps-data/annotations/abagen/genepc1/fsaverage/source-abagen_desc-genepc1_space-fsaverage_den-10k_hemi-L_feature.func.gii', '/Users/kevinhuang/neuromaps-data/annotations/abagen/genepc1/fsaverage/source-abagen_desc-genepc1_space-fsaverage_den-10k_hemi-R_feature.func.gii']\n"
          ]
        }
      ],
      "source": [
        "abagen = datasets.fetch_annotation(source='abagen', desc='genepc1')\n",
        "print(abagen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the returned annotation ``abagen`` is a dictionary. We can subset\n",
        "the dictionary with the appropriate key or, if we know that our query is\n",
        "going to return only one annotation, also provide the `return_single=True`\n",
        "argument to the fetch call:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[References] Please cite the following papers if you are using this data:\n",
            "\n",
            "  For {'source': 'abagen', 'desc': 'genepc1', 'space': 'fsaverage', 'den': '10k'}:\n",
            "  [primary]:\n",
            "    Michael J Hawrylycz, Ed S Lein, Angela L Guillozet-Bongaarts, Elaine H Shen, Lydia Ng, Jeremy A Miller, Louie N Van De Lagemaat, Kimberly A Smith, Amanda Ebbert, Zackery L Riley, and others. An anatomically comprehensive atlas of the adult human brain transcriptome. Nature, 489(7416):391, 2012.\n",
            "    Ross D Markello, Aurina Arnatkeviciute, Jean-Baptiste Poline, Ben D Fulcher, Alex Fornito, and Bratislav Misic. Standardizing workflows in imaging transcriptomics with the abagen toolbox. eLife, 10:e72129, 2021.\n",
            "  [secondary]:\n",
            "    \n",
            "['/Users/kevinhuang/neuromaps-data/annotations/abagen/genepc1/fsaverage/source-abagen_desc-genepc1_space-fsaverage_den-10k_hemi-L_feature.func.gii', '/Users/kevinhuang/neuromaps-data/annotations/abagen/genepc1/fsaverage/source-abagen_desc-genepc1_space-fsaverage_den-10k_hemi-R_feature.func.gii']\n"
          ]
        }
      ],
      "source": [
        "abagen = datasets.fetch_annotation(source='abagen', desc='genepc1',\n",
        "                                   return_single=True)\n",
        "print(abagen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And that's it! This example provided a quick overview on how to fetch the\n",
        "various atlases and datasets provided with ``neuromaps``. For more\n",
        "information please refer to the `API reference <ref_datasets>`.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dsc80",
      "language": "python",
      "name": "dsc80"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
